{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0576f6-ad62-4043-9b44-aa6cb1c55ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\momin\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\momin\\anaconda3\\lib\\site-packages (0.3.61)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\momin\\anaconda3\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langgraph in c:\\users\\momin\\anaconda3\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: gradio in c:\\users\\momin\\anaconda3\\lib\\site-packages (5.31.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain-core) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\momin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\momin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\momin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langgraph) (2.0.26)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langgraph) (0.2.1)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langgraph) (0.1.70)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.10.1 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (1.10.1)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.32.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.11.11)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio) (0.34.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio-client==1.10.1->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\momin\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.4)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\users\\momin\\anaconda3\\lib\\site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\momin\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install necessary libraries\n",
    "!pip install langchain langchain-core langchain-community langgraph gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beaae421-2fc8-4e2f-bbf8-8ff669ff7b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\momin\\AppData\\Local\\Temp\\ipykernel_23208\\1814625557.py:17: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\", temperature=0.7) # Added temperature for a bit more creativity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local LLM (Ollama model: llama3) initialized.\n",
      "\n",
      "--- Testing Ollama LLM connection ---\n",
      "LLM Test Response: In Artificial Intelligence (AI), a Multi-Agent System (MAS) refers to a system where multiple autonomous agents interact and cooperate with each other...\n",
      "--- Ollama LLM connection successful! ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Imports and Ollama LLM Setup\n",
    "\n",
    "import os\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# NEW: Import for Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- Initialize the Local Language Model (Ollama) ---\n",
    "# IMPORTANT:\n",
    "# 1. Ensure Ollama is running in your terminal BEFORE starting Jupyter: `ollama serve`\n",
    "# 2. Ensure you have downloaded your desired model: `ollama pull llama3` (or mistral, phi3 etc.)\n",
    "# 3. Replace 'llama3' below with the actual model name you pulled if different.\n",
    "llm = ChatOllama(model=\"llama3\", temperature=0.7) # Added temperature for a bit more creativity\n",
    "print(f\"Local LLM (Ollama model: {llm.model}) initialized.\")\n",
    "\n",
    "# --- Quick LLM Test ---\n",
    "try:\n",
    "    print(\"\\n--- Testing Ollama LLM connection ---\")\n",
    "    response = llm.invoke(\"Briefly explain the concept of multi-agent systems in AI.\")\n",
    "    print(f\"LLM Test Response: {response.content[:150]}...\") # Print first 150 chars\n",
    "    print(\"--- Ollama LLM connection successful! ---\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: Could not connect to Ollama LLM or model not found: {e}\")\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"1. Ollama server is running (open a terminal and type `ollama serve`).\")\n",
    "    print(\"2. You have pulled the specified model (e.g., `ollama pull llama3`).\")\n",
    "    print(\"3. The model name in ChatOllama matches the one you pulled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9651cd-a33b-42fe-8169-fd448350756e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlannerState and Node functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define Planner State and Enhanced Node Functions\n",
    "\n",
    "class PlannerState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    city: str\n",
    "    interests: List[str]\n",
    "    itinerary: str\n",
    "\n",
    "# --- Define Agent Functions (Nodes) ---\n",
    "# These functions will be called by LangGraph\n",
    "\n",
    "def input_city_node(state: PlannerState):\n",
    "    \"\"\"Placeholder for the 'get city' step.\"\"\"\n",
    "    print(\"--- Agent: Preparing for City Input ---\")\n",
    "    # In a real multi-agent system, this might involve an agent prompting for city.\n",
    "    # For this Gradio app, the city comes directly from the UI.\n",
    "    return state\n",
    "\n",
    "def input_interests_node(state: PlannerState):\n",
    "    \"\"\"Placeholder for the 'get interests' step.\"\"\"\n",
    "    print(f\"--- Agent: Preparing for Interests Input for {state.get('city')} ---\")\n",
    "    # Similarly, interests come from the UI.\n",
    "    return state\n",
    "\n",
    "def create_itinerary_node(state: PlannerState):\n",
    "    \"\"\"Uses the LLM to generate a travel itinerary.\"\"\"\n",
    "    print(\"--- Agent: Generating Itinerary with Local LLM ---\")\n",
    "    city = state[\"city\"]\n",
    "    interests = \", \".join(state[\"interests\"]) if state[\"interests\"] else \"general sightseeing\"\n",
    "\n",
    "    # --- ENHANCED PROMPT FOR STRUCTURED OUTPUT ---\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert travel planner. Your task is to create a detailed 3-day travel itinerary \"\n",
    "            \"for the given city and interests. The itinerary MUST be structured clearly with specific \"\n",
    "            \"daily labels and time-based activities (e.g., Morning, Afternoon, Evening). \"\n",
    "            \"Include specific suggestions for attractions, food, and activities relevant to the interests. \"\n",
    "            \"Ensure the output is easy to read and follows a consistent format.\"\n",
    "        )),\n",
    "        (\"user\", (\n",
    "            f\"Plan a 3-day trip to {city} with the following interests: {interests}. \"\n",
    "            \"Format the itinerary as follows:\\n\\n\"\n",
    "            \"**Day 1: [Theme/Area for Day 1]**\\n\"\n",
    "            \"- Morning: [Activity 1]\\n\"\n",
    "            \"- Afternoon: [Activity 2]\\n\"\n",
    "            \"- Evening: [Activity 3]\\n\\n\"\n",
    "            \"**Day 2: [Theme/Area for Day 2]**\\n\"\n",
    "            \"- Morning: [Activity 1]\\n\"\n",
    "            \"- Afternoon: [Activity 2]\\n\"\n",
    "            \"- Evening: [Activity 3]\\n\\n\"\n",
    "            \"**Day 3: [Theme/Area for Day 3]**\\n\"\n",
    "            \"- Morning: [Activity 1]\\n\"\n",
    "            \"- Afternoon: [Activity 2]\\n\"\n",
    "            \"- Evening: [Activity 3]\\n\\n\"\n",
    "            \"Include practical tips if helpful (e.g., best way to get around).\"\n",
    "        ))\n",
    "    ])\n",
    "    # --- END ENHANCED PROMPT ---\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    try:\n",
    "        response = chain.invoke({\"city\": city, \"interests\": interests})\n",
    "        itinerary = response.content\n",
    "        print(\"\\n--- Agent: Itinerary Generated by Local LLM! ---\")\n",
    "    except Exception as e:\n",
    "        itinerary = (f\"Error generating itinerary with local LLM: {e}\\n\"\n",
    "                     \"Please ensure Ollama is running and the model is loaded correctly.\")\n",
    "        print(f\"\\n--- Agent: Error during Itinerary Generation ---\")\n",
    "\n",
    "    return {\"itinerary\": itinerary, \"messages\": state.get(\"messages\", []) + [AIMessage(content=itinerary)]}\n",
    "\n",
    "print(\"PlannerState and Node functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ca75a3-1349-4063-ab5e-05b72f3da299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph workflow compiled.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create and Compile the LangGraph Graph\n",
    "\n",
    "workflow = StateGraph(PlannerState)\n",
    "\n",
    "workflow.add_node(\"get_city\", input_city_node)\n",
    "workflow.add_node(\"get_interests\", input_interests_node)\n",
    "workflow.add_node(\"generate_itinerary\", create_itinerary_node)\n",
    "\n",
    "workflow.set_entry_point(\"get_city\")\n",
    "\n",
    "workflow.add_edge(\"get_city\", \"get_interests\")\n",
    "workflow.add_edge(\"get_interests\", \"generate_itinerary\")\n",
    "workflow.add_edge(\"generate_itinerary\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"LangGraph workflow compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47325500-024b-4861-8ce5-63b46c0c4ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running planner for City: Kyoto, Interests: temples, gardens, traditional culture, food\n",
      "Please be patient, local LLM inference can take some time depending on your hardware.\n",
      "--- Agent: Preparing for City Input ---\n",
      "--- Agent: Preparing for Interests Input for Kyoto ---\n",
      "--- Agent: Generating Itinerary with Local LLM ---\n",
      "\n",
      "--- Agent: Itinerary Generated by Local LLM! ---\n",
      "\n",
      "--- Final Itinerary ---\n",
      "Here is a suggested 3-day itinerary for Kyoto:\n",
      "\n",
      "**Day 1: Fushimi and Southern Kyoto**\n",
      "- Morning: Visit the iconic Fushimi Inari Shrine (), famous for its thousands of vermilion torii gates. Take the mountain path up to the shrine's summit for stunning views of the city. (9:00 AM - 11:00 AM)\n",
      "- Afternoon: Explore the nearby Tofuku-ji Temple (), a Zen temple with beautiful gardens and a serene atmosphere. Take a stroll around the adjacent Higashiyama neighborhood, known for its traditional shops and cafes. (11:30 AM - 2:30 PM)\n",
      "- Evening: Enjoy a traditional Kyoto-style kaiseki dinner at Gion Nanba, a highly-regarded restaurant in the heart of Gion district. Be sure to reserve ahead of time. (6:00 PM - 8:00 PM)\n",
      "\n",
      "**Day 2: Central Kyoto and Kiyomizu-dera**\n",
      "- Morning: Visit the iconic Kiyomizu-dera Temple (), a UNESCO World Heritage site and one of Japan's most famous temples. Take in the breathtaking views of the city from the temple's wooden stage. (9:30 AM - 11:30 AM)\n",
      "- Afternoon: Explore the adjacent Hieizan Enryaku-ji Temple (), a historic temple complex with beautiful gardens and a peaceful atmosphere. Take a stroll around the nearby Ginkaku-ji Temple () and its serene garden. (12:00 PM - 3:00 PM)\n",
      "- Evening: Experience traditional Japanese theater, such as Noh or Kabuki, at the Kyoto Handicraft Center's Theater. Check schedules and availability in advance. (6:30 PM - 8:30 PM)\n",
      "\n",
      "**Day 3: Arashiyama and Western Kyoto**\n",
      "- Morning: Visit the stunning Tenryu-ji Temple (), a UNESCO World Heritage site with beautiful gardens and traditional architecture. Take a stroll along the nearby Katsura River, lined with cherry blossom trees in spring or maple leaves in autumn. (9:30 AM - 11:30 AM)\n",
      "- Afternoon: Explore the famous Bamboo Grove () and take a leisurely walk through the serene Arashiyama neighborhood. Visit the nearby Togetsu Bridge (), a popular spot for cherry blossom viewing. (12:00 PM - 3:00 PM)\n",
      "- Evening: Enjoy a farewell dinner at Gion Sasaki, a cozy restaurant serving traditional Kyoto-style cuisine. Be sure to reserve ahead of time. (6:30 PM - 8:30 PM)\n",
      "\n",
      "Practical tips:\n",
      "\n",
      "* Getting around: Kyoto has an efficient public transportation system, including buses and trains. Consider purchasing a prepaid IC card like ICOCA or SUICA for easy travel.\n",
      "* Food: Try local specialties like kaiseki dinner, shojin-ryori (Buddhist vegetarian cuisine), or traditional sweets at shops like Gion Nanba or Gion Sasaki.\n",
      "* Weather: Kyoto can be hot and humid in summer or cold and snowy in winter. Pack accordingly and bring sunscreen, rain gear, and layers.\n",
      "* Respect local customs: Dress modestly when visiting temples, remove shoes before entering homes or temples, and follow any instructions from temple staff.\n",
      "\n",
      "Enjoy your trip to Kyoto!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run the Graph (Interactive Test with Local LLM)\n",
    "\n",
    "# Define your desired city and interests for this test run\n",
    "test_city = \"Kyoto\"\n",
    "test_interests = [\"temples\", \"gardens\", \"traditional culture\", \"food\"]\n",
    "\n",
    "# Initialize the state for this run\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=f\"User wants to visit {test_city} with interests: {', '.join(test_interests)}\")],\n",
    "    \"city\": test_city,\n",
    "    \"interests\": test_interests,\n",
    "    \"itinerary\": \"\"\n",
    "}\n",
    "\n",
    "print(f\"Running planner for City: {test_city}, Interests: {', '.join(test_interests)}\")\n",
    "print(\"Please be patient, local LLM inference can take some time depending on your hardware.\")\n",
    "\n",
    "# Invoke the graph with the initial state\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n--- Final Itinerary ---\")\n",
    "print(final_state[\"itinerary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a275288-d472-4468-b2c3-38d784e377d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\momin\\anaconda3\\Lib\\site-packages\\gradio\\interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 6: Gradio App Integration with Local LLM (Streaming Output)\n",
    "\n",
    "import gradio as gr\n",
    "# ... (rest of your imports and code from previous cells are assumed to be run) ...\n",
    "\n",
    "# Make sure `llm` is defined from Cell 2 and `app` from Cell 4.\n",
    "\n",
    "def stream_planner_output(city_input: str, interests_input: str):\n",
    "    if not city_input:\n",
    "        yield \"Please enter a city.\"\n",
    "        return\n",
    "\n",
    "    processed_interests = [interest.strip() for interest in interests_input.split(',') if interest.strip()]\n",
    "\n",
    "    # --- RE-USING THE ENHANCED PROMPT ---\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert travel planner. Your task is to create a detailed 3-day travel itinerary \"\n",
    "            \"for the given city and interests. The itinerary MUST be structured clearly, with specific \"\n",
    "            \"daily labels and time-based activities (e.g., Morning, Afternoon, Evening). \"\n",
    "            \"Include specific suggestions for attractions, food, and activities relevant to the interests. \"\n",
    "            \"Ensure the output is easy to read and follows a consistent format.\"\n",
    "        )),\n",
    "        (\"user\", (\n",
    "            f\"Plan a 3-day trip to {city_input} with the following interests: {', '.join(processed_interests)}. \"\n",
    "            \"Format the itinerary as follows:\\n\\n\"\n",
    "            \"**Day 1: [Theme/Area for Day 1]**\\n\"\n",
    "            \"- Morning: [Activity 1]\\n\"\n",
    "            \"- Afternoon: [Activity 2]\\n\"\n",
    "            \"- Evening: [Activity 3]\\n\\n\"\n",
    "            \"**Day 2: [Theme/Area for Day 2]**\\n\"\n",
    "            \"- Morning: [Activity 1]\\n\"\n",
    "            \"- Afternoon: [Activity 2]\\n\"\n",
    "            \"- Evening: [Activity 3]\\n\\n\"\n",
    "            \"**Day 3: [Theme/Area for Day 3]**\\n\"\n",
    "            \"- Morning: [Activity 1]\\n\"\n",
    "            \"- Afternoon: [Activity 2]\\n\"\n",
    "            \"- Evening: [Activity 3]\\n\\n\"\n",
    "            \"Include practical tips if helpful (e.g., best way to get around).\"\n",
    "        ))\n",
    "    ])\n",
    "    # --- END ENHANCED PROMPT ---\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "\n",
    "    current_itinerary_text = \"\"\n",
    "    yield \"Generating your personalized itinerary... This might take a moment with a local LLM.\"\n",
    "\n",
    "    try:\n",
    "        for chunk in chain.stream({\"city\": city_input, \"interests\": ', '.join(processed_interests)}):\n",
    "            content = chunk.content\n",
    "            if content:\n",
    "                current_itinerary_text += content\n",
    "                yield current_itinerary_text\n",
    "    except Exception as e:\n",
    "        yield f\"An error occurred during itinerary generation: {e}\\nEnsure Ollama is running and the model is available.\"\n",
    "\n",
    "\n",
    "# --- Create the Gradio Interface ---\n",
    "iface = gr.Interface(\n",
    "    fn=stream_planner_output,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"City (e.g., Tokyo, Rome)\", placeholder=\"Enter your destination city\"),\n",
    "        gr.Textbox(label=\"Interests (comma-separated, e.g., food, history, art)\", placeholder=\"museums, parks, shopping\")\n",
    "    ],\n",
    "    outputs=gr.Markdown(label=\"Your Travel Itinerary\"),\n",
    "    title=\"Multi-Agent Travel Planner\",\n",
    "    description=\"Plan your next adventure with a local AI agent! Enter your city and interests to get a personalized 3-day itinerary.\",\n",
    "    examples=[\n",
    "        [\"Sydney\", \"beaches, opera, nature\"],\n",
    "        [\"Rome\", \"ancient ruins, pizza, art\"],\n",
    "        [\"Amsterdam\", \"canals, cycling, museums\"]\n",
    "    ],\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app directly within the Jupyter Notebook\n",
    "if __name__ == \"__main__\":\n",
    "    # This is the line that creates the public URL:\n",
    "    iface.launch(inbrowser=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5772c-178c-4d2b-953d-54deaa464e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
